
import React, { useState, useEffect, useCallback } from 'react';
import { AgentLayout } from '../../AgentLayout';
import { ChartIcon } from '../../../icons';
import { ChatPanel } from './ChatPanel';
import { ReportCanvas } from './ReportCanvas';
import { StepId, TechEvalSessionData, ChatMessage, ReportSection } from './types';
import { getPromptDetail, streamChatCompletions } from '../../../../api/stratify';
import { searchSemanticSegments } from '../../../../api/intelligence';
import { AGENTS } from '../../../../agentConfig';

interface TechDecisionAssistantProps {
    onBack?: () => void;
}

const DEFAULT_SECTIONS: Record<StepId, ReportSection> = {
    init: { id: 'init', title: 'åˆå§‹åŒ–', status: 'done', markdown: '' },
    route: { id: 'route', title: 'æŠ€æœ¯è·¯çº¿', status: 'pending', markdown: '' },
    risk: { id: 'risk', title: 'é£é™©è¯„ä¼°', status: 'pending', markdown: '' },
    solution: { id: 'solution', title: 'è§£å†³æ–¹æ¡ˆ', status: 'pending', markdown: '' },
    compare: { id: 'compare', title: 'ç»¼åˆå†³ç­–', status: 'pending', markdown: '' },
};

const STEPS: StepId[] = ['init', 'route', 'risk', 'solution', 'compare'];

const extractCleanHtml = (text: string) => {
    let cleanText = text.replace(/<think>[\s\S]*?<\/think>/gi, '');
    const codeBlockMatch = cleanText.match(/```html\s*([\s\S]*?)```/i);
    if (codeBlockMatch) return codeBlockMatch[1];
    
    const rawStart = cleanText.search(/<!DOCTYPE|<html|<div|<section/i);
    if (rawStart !== -1) return cleanText.substring(rawStart);
    return '';
};

const TechDecisionAssistant: React.FC<TechDecisionAssistantProps> = ({ onBack }) => {
    const [data, setData] = useState<TechEvalSessionData>({
        techName: '',
        searchQueries: [],
        currentStepIndex: 0,
        sections: JSON.parse(JSON.stringify(DEFAULT_SECTIONS)),
        messages: [{
            id: 'welcome',
            role: 'assistant',
            content: 'æˆ‘æ˜¯æ‚¨çš„æŠ€æœ¯å†³ç­–è¯„ä¼°åŠ©æ‰‹ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³è¦è¯„ä¼°çš„æŠ€æœ¯åç§°ï¼ˆä¾‹å¦‚ï¼š800Vç¢³åŒ–ç¡…å¹³å°ã€åŠå›ºæ€ç”µæ± ç­‰ï¼‰ã€‚',
            timestamp: Date.now()
        }]
    });
    
    const [isGenerating, setIsGenerating] = useState(false);

    const currentStepId = STEPS[data.currentStepIndex];
    const currentSection = data.sections[currentStepId];

    // Helper: Add Message
    const addMessage = (role: 'user' | 'assistant', content: string) => {
        const msg: ChatMessage = { id: crypto.randomUUID(), role, content, timestamp: Date.now() };
        setData(prev => ({ ...prev, messages: [...prev.messages, msg] }));
    };

    // Helper: Update Section
    const updateSection = (stepId: StepId, updates: Partial<ReportSection>) => {
        setData(prev => ({
            ...prev,
            sections: {
                ...prev.sections,
                [stepId]: { ...prev.sections[stepId], ...updates }
            }
        }));
    };

    // --- STEP 0: Initialization ---
    const runInitStep = async (input: string) => {
        setIsGenerating(true);
        updateSection('init', { status: 'generating' });
        
        try {
            const prompt = await getPromptDetail('tech_eval_init');
            const filledPrompt = prompt.content.replace('{{ user_input }}', input);

            let jsonBuffer = "";
            await streamChatCompletions({
                model: 'zhipu@glm-4-flash',
                messages: [{ role: 'user', content: filledPrompt }],
                stream: true,
                temperature: 0.1
            }, (chunk) => {
                if (chunk.content) jsonBuffer += chunk.content;
            });

            // Parse JSON
            let parsed;
            try {
                // Try to find JSON block
                const match = jsonBuffer.match(/```json([\s\S]*?)```/) || jsonBuffer.match(/\{[\s\S]*\}/);
                const cleanJson = match ? match[0].replace(/```json/g, '').replace(/```/g, '') : jsonBuffer;
                parsed = JSON.parse(cleanJson);
            } catch (e) {
                console.error("JSON Parse Error", e);
                // Fallback if simple extraction failed
                parsed = { tech_name: input, search_queries: [input] };
            }

            setData(prev => ({
                ...prev,
                techName: parsed.tech_name,
                techDefinition: parsed.definition,
                searchQueries: parsed.search_queries || [parsed.tech_name],
                currentStepIndex: 1, // Move to next step immediately
            }));
            
            addMessage('assistant', `å·²ç¡®è®¤è¯„ä¼°å¯¹è±¡ï¼š**${parsed.tech_name}**ã€‚\nåˆæ­¥å®šä¹‰ï¼š${parsed.definition}\n\næ­£åœ¨å¯åŠ¨ç¬¬ä¸€é˜¶æ®µåˆ†æï¼šæŠ€æœ¯è·¯çº¿ä¸ç«å“é”šå®š...`);
            
            // Auto trigger next step
            setTimeout(() => runGenerationStep('route', parsed.tech_name, parsed.search_queries), 500);

        } catch (e: any) {
            addMessage('assistant', `åˆå§‹åŒ–å¤±è´¥: ${e.message}`);
        } finally {
            setIsGenerating(false);
            updateSection('init', { status: 'done' });
        }
    };

    // --- GENERIC GENERATION STEP ---
    const runGenerationStep = async (stepId: StepId, techName: string, queries: string[], userInstructions?: string) => {
        setIsGenerating(true);
        updateSection(stepId, { status: 'generating', markdown: '' });
        
        try {
            // 1. RAG Search (Simulated or Real)
            let ragContext = "";
            if (!userInstructions) { // Only search on first run of the step, or always? Let's search always for now to be robust.
                const queryStr = queries.join(' ') + ` ${stepId} æŠ€æœ¯è¯„ä¼°`;
                const searchRes = await searchSemanticSegments({ 
                    query_text: queryStr, 
                    page: 1, 
                    page_size: 5,
                    similarity_threshold: 0.3
                });
                if (searchRes.items && searchRes.items.length > 0) {
                    ragContext = searchRes.items.map((it, idx) => `[èµ„æ–™${idx+1}] ${it.title}: ${it.content}`).join('\n\n');
                }
            }

            // 2. Fetch Prompt
            const promptMap: Record<StepId, string> = {
                'init': 'tech_eval_init',
                'route': 'tech_eval_step1_route',
                'risk': 'tech_eval_step2_risk',
                'solution': 'tech_eval_step3_solution',
                'compare': 'tech_eval_step4_compare'
            };
            
            const promptName = promptMap[stepId];
            const promptTemplate = await getPromptDetail(promptName);
            
            // 3. Context Preparation
            // Gather previous summaries if needed
            const prevSummary = stepId === 'risk' ? data.sections['route'].markdown.slice(0, 500) :
                                stepId === 'solution' ? data.sections['risk'].markdown.slice(0, 500) :
                                stepId === 'compare' ? (data.sections['route'].markdown + data.sections['risk'].markdown + data.sections['solution'].markdown).slice(0, 1000) : '';

            let filledPrompt = promptTemplate.content
                .replace(/{{ tech_name }}/g, techName)
                .replace(/{{ retrieved_info }}/g, ragContext || 'æš‚æ— æ›´å¤šå¤–éƒ¨èµ„æ–™ï¼Œè¯·åŸºäºæ‚¨çš„ä¸“ä¸šçŸ¥è¯†åˆ†æã€‚')
                .replace(/{{ step1_summary }}/g, prevSummary) // for risk
                .replace(/{{ step2_summary }}/g, prevSummary) // for solution
                .replace(/{{ steps_summary }}/g, prevSummary); // for compare
            
            if (userInstructions) {
                filledPrompt += `\n\n**ç”¨æˆ·è¡¥å……æŒ‡ä»¤ï¼ˆè¯·é‡ç‚¹å…³æ³¨å¹¶ä¿®æ”¹ï¼‰ï¼š**\n${userInstructions}`;
            }

            // 4. Stream LLM
            let fullContent = "";
            await streamChatCompletions({
                model: 'zhipu@glm-4-flash',
                messages: [{ role: 'user', content: filledPrompt }],
                stream: true,
                temperature: 0.2
            }, (chunk) => {
                if (chunk.content) {
                    fullContent += chunk.content;
                    // Real-time update markdown (HTML extraction happens in render or post-process)
                    // We strip the HTML block from markdown display if needed, but for now lets keep it raw or process it
                    // Actually, ReportCanvas handles HTML extraction for the widget? 
                    // Let's separate HTML here for cleaner storage
                    const cleanHtml = extractCleanHtml(fullContent);
                    // Remove HTML code block from markdown to avoid duplication in text view
                    // const cleanMarkdown = fullContent.replace(/```html[\s\S]*?```/gi, '').replace(/<html>[\s\S]*?<\/html>/gi, '');
                    
                    updateSection(stepId, { 
                        markdown: fullContent, 
                        html: cleanHtml 
                    });
                }
            }, undefined, undefined, AGENTS.TECH_DECISION_ASSISTANT); // Pass Agent ID for billing

            updateSection(stepId, { status: 'review' });
            addMessage('assistant', `**${data.sections[stepId].title}** è‰ç¨¿å·²ç”Ÿæˆã€‚è¯·æŸ¥é˜…å·¦ä¾§æŠ¥å‘Šã€‚å¦‚æœ‰ä¿®æ”¹æ„è§è¯·ç›´æ¥è¾“å…¥ï¼Œæˆ–ç‚¹å‡»â€œç¡®è®¤â€è¿›å…¥ä¸‹ä¸€é˜¶æ®µã€‚`);

        } catch (e: any) {
            console.error(e);
            addMessage('assistant', `ç”Ÿæˆå¤±è´¥: ${e.message}`);
            updateSection(stepId, { status: 'pending' }); // Reset to allow retry
        } finally {
            setIsGenerating(false);
        }
    };

    // --- Handlers ---
    const handleSendMessage = (text: string) => {
        addMessage('user', text);
        
        if (currentStepId === 'init') {
            runInitStep(text);
        } else if (currentSection.status === 'review') {
            // User wants to modify the current step
            runGenerationStep(currentStepId, data.techName, data.searchQueries, text);
        } else {
            // General chat or instructions while generating?
            // If generating, input is disabled.
        }
    };

    const handleConfirmStep = () => {
        updateSection(currentStepId, { status: 'done' });
        
        if (data.currentStepIndex < STEPS.length - 1) {
            const nextIndex = data.currentStepIndex + 1;
            const nextStepId = STEPS[nextIndex];
            
            setData(prev => ({ ...prev, currentStepIndex: nextIndex }));
            addMessage('assistant', `é˜¶æ®µç¡®è®¤ã€‚æ­£åœ¨å¯åŠ¨ä¸‹ä¸€é˜¶æ®µï¼š**${data.sections[nextStepId].title}**...`);
            
            // Auto start next step
            setTimeout(() => {
                runGenerationStep(nextStepId, data.techName, data.searchQueries);
            }, 500);
        } else {
            addMessage('assistant', `ğŸ‰ æ­å–œï¼å…¨æµç¨‹è¯„ä¼°å·²å®Œæˆã€‚æ‚¨å¯ä»¥å¯¼å‡ºæŠ¥å‘Šæˆ–ç»§ç»­ä¸æˆ‘å¯¹è¯å®Œå–„ç»†èŠ‚ã€‚`);
        }
    };

    const handleRegenerateStep = () => {
        runGenerationStep(currentStepId, data.techName, data.searchQueries, "è¯·é‡æ–°ç”Ÿæˆæœ¬èŠ‚å†…å®¹ï¼Œå°è¯•ä¸åŒçš„åˆ†æè§’åº¦ã€‚");
    };

    return (
        <AgentLayout 
            title="æŠ€æœ¯å†³ç­–è¯„ä¼°åŠ©æ‰‹" 
            icon={ChartIcon} 
            onBack={onBack || (() => window.history.back())}
        >
            <div className="flex h-full overflow-hidden">
                {/* Left Canvas (60%) */}
                <div className="flex-1 min-w-0 border-r border-slate-200">
                    <ReportCanvas 
                        sections={data.sections}
                        currentStep={currentStepId}
                        techName={data.techName}
                    />
                </div>

                {/* Right Chat (40%) */}
                <div className="w-[450px] flex-shrink-0 bg-white shadow-xl z-10">
                    <ChatPanel 
                        messages={data.messages}
                        onSendMessage={handleSendMessage}
                        isGenerating={isGenerating}
                        currentStep={currentStepId}
                        stepStatus={currentSection.status}
                        onConfirmStep={handleConfirmStep}
                        onRegenerateStep={handleRegenerateStep}
                    />
                </div>
            </div>
        </AgentLayout>
    );
};

export default TechDecisionAssistant;
